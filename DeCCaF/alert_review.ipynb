{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import yaml\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "baf_model_score = pd.read_parquet('./data/BAF_deployment_score.parquet')\n",
    "baf = pd.read_parquet('./data/BAF.parquet')\n",
    "\n",
    "with open('./ml_model/model/model_properties.pickle', 'rb') as infile:\n",
    "        model_properties = pickle.load(infile)\n",
    "\n",
    "\n",
    "l = model_properties['threshold']/(1-model_properties['threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = baf.loc[baf['month'] == 7].index\n",
    "val_index = baf.loc[baf['month'] == 6].index\n",
    "\n",
    "val = baf_model_score.loc[val_index]\n",
    "test = baf_model_score.loc[test_index]\n",
    "train = baf_model_score.drop(val_index).drop(test_index)\n",
    "\n",
    "data_cfg_path = './data/dataset_cfg.yaml'\n",
    "\n",
    "with open(data_cfg_path, 'r') as infile:\n",
    "    data_cfg = yaml.safe_load(infile)\n",
    "\n",
    "cat_dict = data_cfg['categorical_dict']\n",
    "\n",
    "def cat_checker(data, features, cat_dict):\n",
    "    new_data = data.copy()\n",
    "    for feature in features:\n",
    "        if new_data[feature].dtype.categories.to_list() != cat_dict[feature]:\n",
    "            new_data[feature] = pd.Categorical(new_data[feature].values, categories=cat_dict[feature])\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "CATEGORICAL_COLS = data_cfg['data_cols']['categorical']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "a = dict()\n",
    "for direc in os.listdir('./testbed/test/'):\n",
    "    if os.path.isfile(f'./testbed/test/{direc}'):\n",
    "        continue\n",
    "    a[direc] = dict()\n",
    "    a[direc]['bat'] = pd.read_csv('./testbed/test/' + direc + '/batches.csv')\n",
    "    a[direc]['cap'] = pd.read_csv('./testbed/test/' + direc + '/capacity.csv')\n",
    "\n",
    "\n",
    "test_env_df = pd.DataFrame(columns = ['training_seed',\n",
    "                                      'model',\n",
    "                                      'batch_size',\n",
    "                                      'batch_seed', \n",
    "                                      'absence_rate', \n",
    "                                      'absence_seed', \n",
    "                                      'distribution', \n",
    "                                      'distribution_std', \n",
    "                                      'distribution_seed', \n",
    "                                      'deferral_rate',\n",
    "                                      'pool',\n",
    "                                      'n_errors',\n",
    "                                      'tp',\n",
    "                                      'fp',\n",
    "                                      'fn',\n",
    "                                      'tn',\n",
    "                                      'tpr',\n",
    "                                      'fpr',\n",
    "                                      'fpr_disp'])\n",
    "\n",
    "seeds = os.listdir('./deferral_results')\n",
    "if not os.path.isfile('test_results.parquet'):\n",
    "    for seed in seeds:\n",
    "        if seed == 'random':\n",
    "            continue\n",
    "        models = os.listdir(f'./deferral_results/{seed}')\n",
    "        for model in models:\n",
    "                for test_env_id in a:\n",
    "                    direc = test_env_id\n",
    "                    test_env_id = test_env_id.split('#')\n",
    "                    if test_env_id[0].split('_')[0] == 'large':\n",
    "                        batch_size = 5000\n",
    "                    elif test_env_id[0].split('_')[0] == 'small':\n",
    "                        batch_size = 1000\n",
    "\n",
    "                    batch_seed = test_env_id[0].split('-')[1]\n",
    "\n",
    "                    if test_env_id[1].split('_')[0] == 'homogenous':\n",
    "                        distribution = 'homogenous'\n",
    "                        distribution_seed = 'NA'\n",
    "                        distribution_std = 'NA'\n",
    "                    else:\n",
    "                        distribution = 'variable'\n",
    "                        distribution_seed = test_env_id[1].split('_')[0].split('-')[1]\n",
    "                        distribution_std = '0.2'\n",
    "\n",
    "                    if test_env_id[1].split('_')[1] == 'fullteam':\n",
    "                        absence = 0\n",
    "                        absence_seed = 'NA'\n",
    "                    else:\n",
    "                        absence = 0.5\n",
    "                        absence_seed = test_env_id[1].split('_')[1].split('-')[1]\n",
    "                    \n",
    "                    if test_env_id[1].split('_')[2] == 'def20':\n",
    "                        deferral_rate = 0.2\n",
    "                    else:\n",
    "                        deferral_rate = 0.5\n",
    "\n",
    "                    if test_env_id[1].split('_')[-1] == 'sp':\n",
    "                        exp_pool = 'sparse'\n",
    "                    elif test_env_id[1].split('_')[-1] == 'ma':\n",
    "                        exp_pool = 'agreeing'\n",
    "                    elif test_env_id[1].split('_')[-1] == 'un':\n",
    "                        exp_pool = 'unfair'\n",
    "                    elif test_env_id[1].split('_')[-1] == 'st':\n",
    "                        exp_pool = 'standard'\n",
    "                    else:\n",
    "                        exp_pool = 'all'\n",
    "                        \n",
    "                    d = pd.DataFrame(index = test.index)\n",
    "                    d['prediction'] = 0\n",
    "                    reviews = pd.read_parquet(f'./deferral_results/{seed}/{model}/{direc}/results.parquet')\n",
    "                    d.loc[reviews.index,'prediction'] = reviews['prediction']\n",
    "\n",
    "                    n_errors = ( d['prediction'] != test['fraud_bool']).astype(int).mean()\n",
    "                    tn, fp, fn, tp = confusion_matrix(y_true = test['fraud_bool'], y_pred = d['prediction']).ravel()\n",
    "                    tpr = tp/(tp+fn)\n",
    "                    fpr = fp/(fp+tn)\n",
    "\n",
    "                    old_ix = test.loc[test['customer_age'] >= 50].index\n",
    "                    yng_ix = test.loc[test['customer_age'] < 50].index\n",
    "\n",
    "                    label = test['fraud_bool']\n",
    "\n",
    "                    old_pred = d['prediction'].loc[old_ix]\n",
    "                    old_label = label.loc[old_ix]\n",
    "                    fp_old = ((old_pred == 1) & (old_label == 0)).astype(int).sum()\n",
    "                    tn_old = ((old_pred == 0) & (old_label == 0)).astype(int).sum()\n",
    "\n",
    "                    yng_pred = d['prediction'].loc[yng_ix]\n",
    "                    yng_label = label.loc[yng_ix]\n",
    "                    fp_yng = ((yng_pred == 1) & (yng_label == 0)).astype(int).sum()\n",
    "                    tn_yng = ((yng_pred == 0) & (yng_label == 0)).astype(int).sum()\n",
    "\n",
    "                    fpr_yng = fp_yng/(fp_yng + tn_yng)\n",
    "                    fpr_old = fp_old/(fp_old + tn_old)\n",
    "\n",
    "                    fpr_disp =  fpr_yng/fpr_old\n",
    "                    test_env_df = test_env_df.append(pd.Series([seed,model,batch_size, \n",
    "                                                                batch_seed, \n",
    "                                                                absence,\n",
    "                                                                absence_seed, \n",
    "                                                                distribution, \n",
    "                                                                distribution_std, \n",
    "                                                                distribution_seed, \n",
    "                                                                deferral_rate,\n",
    "                                                                exp_pool,\n",
    "                                                                n_errors,\n",
    "                                                                tp,\n",
    "                                                                fp,\n",
    "                                                                fn,\n",
    "                                                                tn,\n",
    "                                                                tpr,\n",
    "                                                                fpr, \n",
    "                                                                fpr_disp], index = test_env_df.columns), ignore_index = True)\n",
    "                    \n",
    "            \n",
    "        print(test_env_df)\n",
    "        test_results = test_env_df\n",
    "        test_results['loss_0057'] = (l * test_results['fp'] + test_results['fn']).astype('float')\n",
    "        test_results.to_parquet('test_results.parquet')\n",
    "else:\n",
    "    test_results = pd.read_parquet('test_results.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "a = dict()\n",
    "for direc in os.listdir('./testbed/test/'):\n",
    "    if os.path.isfile(f'./testbed/test/{direc}'):\n",
    "        continue\n",
    "    a[direc] = dict()\n",
    "    a[direc]['bat'] = pd.read_csv('./testbed/test/' + direc + '/batches.csv')\n",
    "    a[direc]['cap'] = pd.read_csv('./testbed/test/' + direc + '/capacity.csv')\n",
    "\n",
    "test_env_df = pd.DataFrame(columns = ['model',\n",
    "                                      'batch_size',\n",
    "                                      'batch_seed', \n",
    "                                      'absence_rate', \n",
    "                                      'absence_seed', \n",
    "                                      'distribution', \n",
    "                                      'distribution_std', \n",
    "                                      'distribution_seed', \n",
    "                                      'deferral_rate',\n",
    "                                      'exp_pool',\n",
    "                                      'n_errors',\n",
    "                                      'tp',\n",
    "                                      'fp',\n",
    "                                      'fn',\n",
    "                                      'tn',\n",
    "                                      'tpr',\n",
    "                                      'fpr',\n",
    "                                      'fpr_disp'])\n",
    "models = ['random']\n",
    "if not os.path.isfile('test_results_random.parquet'):\n",
    "    for model in models:\n",
    "            for test_env_id in a:\n",
    "                direc = test_env_id\n",
    "                test_env_id = test_env_id.split('#')\n",
    "                if test_env_id[0].split('_')[0] == 'large':\n",
    "                    batch_size = 5000\n",
    "                elif test_env_id[0].split('_')[0] == 'small':\n",
    "                    batch_size = 1000\n",
    "\n",
    "                batch_seed = test_env_id[0].split('-')[1]\n",
    "\n",
    "                if test_env_id[1].split('_')[0] == 'homogenous':\n",
    "                    distribution = 'homogenous'\n",
    "                    distribution_seed = 'NA'\n",
    "                    distribution_std = 'NA'\n",
    "                else:\n",
    "                    distribution = 'variable'\n",
    "                    distribution_seed = test_env_id[1].split('_')[0].split('-')[1]\n",
    "                    distribution_std = '0.2'\n",
    "\n",
    "                if test_env_id[1].split('_')[1] == 'fullteam':\n",
    "                    absence = 0\n",
    "                    absence_seed = 'NA'\n",
    "                else:\n",
    "                    absence = 0.5\n",
    "                    absence_seed = test_env_id[1].split('_')[1].split('-')[1]\n",
    "                \n",
    "                if test_env_id[1].split('_')[2] == 'def20':\n",
    "                    deferral_rate = 0.2\n",
    "                else:\n",
    "                    deferral_rate = 0.5\n",
    "                \n",
    "                if test_env_id[1].split('_')[-1] == 'sp':\n",
    "                    exp_pool = 'sparse'\n",
    "                elif test_env_id[1].split('_')[-1] == 'ma':\n",
    "                    exp_pool = 'agreeing'\n",
    "                elif test_env_id[1].split('_')[-1] == 'un':\n",
    "                    exp_pool = 'unfair'\n",
    "                elif test_env_id[1].split('_')[-1] == 'st':\n",
    "                    exp_pool = 'standard'\n",
    "                else:\n",
    "                    exp_pool = 'all'\n",
    "                \n",
    "                d = pd.DataFrame(index = test.index)\n",
    "                d['prediction'] = 0\n",
    "                reviews = pd.read_parquet(f'./deferral_results/{model}/{direc}/results.parquet')\n",
    "                d.loc[reviews.index,'prediction'] = reviews['prediction']\n",
    "\n",
    "                n_errors = ( d['prediction'] != test['fraud_bool']).astype(int).mean()\n",
    "                tn, fp, fn, tp = confusion_matrix(y_true = test['fraud_bool'], y_pred = d['prediction']).ravel()\n",
    "                tpr = tp/(tp+fn)\n",
    "                fpr = fp/(fp+tn)\n",
    "\n",
    "                old_ix = test.loc[test['customer_age'] >= 50].index\n",
    "                yng_ix = test.loc[test['customer_age'] < 50].index\n",
    "\n",
    "                label = test['fraud_bool']\n",
    "\n",
    "                old_pred = d['prediction'].loc[old_ix]\n",
    "                old_label = label.loc[old_ix]\n",
    "                fp_old = ((old_pred == 1) & (old_label == 0)).astype(int).sum()\n",
    "                tn_old = ((old_pred == 0) & (old_label == 0)).astype(int).sum()\n",
    "\n",
    "                yng_pred = d['prediction'].loc[yng_ix]\n",
    "                yng_label = label.loc[yng_ix]\n",
    "                fp_yng = ((yng_pred == 1) & (yng_label == 0)).astype(int).sum()\n",
    "                tn_yng = ((yng_pred == 0) & (yng_label == 0)).astype(int).sum()\n",
    "\n",
    "                fpr_yng = fp_yng/(fp_yng + tn_yng)\n",
    "                fpr_old = fp_old/(fp_old + tn_old)\n",
    "\n",
    "                fpr_disp =  fpr_yng/fpr_old\n",
    "                test_env_df = test_env_df.append(pd.Series([model,batch_size, \n",
    "                                                            batch_seed, \n",
    "                                                            absence,\n",
    "                                                            absence_seed, \n",
    "                                                            distribution, \n",
    "                                                            distribution_std, \n",
    "                                                            distribution_seed, \n",
    "                                                            deferral_rate,\n",
    "                                                            exp_pool,\n",
    "                                                            n_errors,\n",
    "                                                            tp,\n",
    "                                                            fp,\n",
    "                                                            fn,\n",
    "                                                            tn,\n",
    "                                                            tpr,\n",
    "                                                            fpr, \n",
    "                                                            fpr_disp], index = test_env_df.columns), ignore_index = True)\n",
    "\n",
    "    test_results_ran = test_env_df\n",
    "    test_results_ran['loss_0057'] = (l * test_results_ran['fp'] + test_results_ran['fn']).astype('float')\n",
    "    test_results_ran.to_parquet('test_results_random.parquet')\n",
    "else:\n",
    "    test_results_ran = pd.read_parquet('test_results_random.parquet')\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = test_results\n",
    "tests_ran = test_results_ran\n",
    "models = ['OvA', 'DeCCaF_greedy', 'DeCCaF_linear']\n",
    "seeds = ['small-1_regular',\n",
    "         'small-2_regular',\n",
    "         'small-3_regular',\n",
    "         'small-4_regular',\n",
    "         'small-5_regular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = pd.DataFrame()\n",
    "ranks['OvA'] = tests.loc[tests['model'] == 'OvA'].groupby(by = ['training_seed', 'batch_size', 'batch_seed', 'absence_rate', 'absence_seed', 'distribution', 'distribution_std', 'distribution_seed', 'deferral_rate', 'pool']).mean().reset_index().loc[:,'loss_0057'].to_numpy()\n",
    "#ranks['ova_ncs'] = tests.loc[tests['model'] == 'ova_ncs'].groupby(by = ['training_seed', 'batch_size', 'batch_seed', 'absence_rate', 'absence_seed', 'distribution', 'distribution_std', 'distribution_seed', 'deferral_rate', 'pool']).mean().reset_index().loc[:,'loss_0057'].to_numpy()\n",
    "\n",
    "ranks['DeCCaF_greedy'] = tests.loc[tests['model'] == 'DeCCaF_greedy'].groupby(by = ['training_seed', 'batch_size', 'batch_seed', 'absence_rate', 'absence_seed', 'distribution', 'distribution_std', 'distribution_seed', 'deferral_rate', 'pool']).mean().reset_index().loc[:,'loss_0057'].to_numpy()\n",
    "ranks['DeCCaF_linear'] = tests.loc[tests['model'] == 'DeCCaF_linear'].groupby(by = ['training_seed', 'batch_size', 'batch_seed', 'absence_rate', 'absence_seed', 'distribution', 'distribution_std', 'distribution_seed', 'deferral_rate', 'pool']).mean().reset_index().loc[:,'loss_0057'].to_numpy()\n",
    "\n",
    "a = []\n",
    "for i in range(5):\n",
    "    a.append(tests_ran.loc[tests_ran['model'] == 'random'].groupby(by = ['batch_size', 'batch_seed', 'absence_rate', 'absence_seed', 'distribution', 'distribution_std', 'distribution_seed', 'deferral_rate', 'exp_pool']).mean().reset_index().loc[:,'loss_0057'].to_numpy())\n",
    "\n",
    "a = np.concatenate(a)\n",
    "\n",
    "ranks['ReL'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = ['OvA', 'DeCCaF_greedy', 'DeCCaF_linear', 'ReL']\n",
    "\n",
    "comps = pd.DataFrame(index=choices, columns=choices)\n",
    "for first in choices:\n",
    "    for second in choices:\n",
    "        comps.loc[first,second] = sum((ranks[first]<ranks[second]).astype(int))/len(ranks)\n",
    "    \n",
    "comps = comps.astype(float).round(2)\n",
    "comps.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_results.loc[test_results['model'] == 'OvA'].mean().loc['loss_0057'] - test_results.loc[test_results['model'] == 'DeCCaF_linear'].mean().loc['loss_0057'])/test_results.loc[test_results['model'] == 'OvA'].mean().loc['loss_0057']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.loc[test_results['model'] == 'OvA'].mean().loc['loss_0057']*0.909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tests_ran.loc[tests_ran['model'] == 'random'].groupby(by = ['batch_size', 'absence_rate', 'distribution', 'deferral_rate', 'exp_pool']).mean().reset_index().loc[:,['batch_size', 'absence_rate', 'distribution', 'deferral_rate', 'exp_pool']]\n",
    "ran = tests_ran[tests_ran['model'] == 'random'].groupby(by = ['batch_size', 'absence_rate', 'distribution', 'deferral_rate', 'exp_pool']).mean().reset_index().loc[:,['batch_size', 'absence_rate', 'distribution', 'deferral_rate', 'exp_pool', 'fpr', 'tpr', 'loss_0057', 'fpr_disp']]\n",
    "ran_std = tests_ran[tests_ran['model'] == 'random'].groupby(by = ['batch_size', 'absence_rate', 'distribution', 'deferral_rate', 'exp_pool']).std().reset_index().loc[:,['batch_size', 'absence_rate', 'distribution', 'deferral_rate', 'exp_pool', 'fpr', 'tpr', 'loss_0057', 'fpr_disp']]\n",
    "\n",
    "results['loss_ReL'] = '$' + ((ran['loss_0057']).round(0)).astype(int).astype(str) + '\\mbox{\\scriptsize{$\\pm ' + ((1.96*ran_std['loss_0057']).round(0)).astype(int).astype(str) + '$} }$'\n",
    "results['PE_ReL'] = '$' + ((ran['fpr_disp']).round(2)).astype(str) \n",
    "results[f'PE_ReL'].loc[results[f'PE_ReL'].str.len() == 4] += '0'\n",
    "results[f'PE_ReL'] += '$'\n",
    "\n",
    "for model in models:\n",
    "    ran = tests.loc[(tests['model'] == model) & (tests['training_seed'] != 'no_restrictions')].groupby(by = ['batch_size', 'absence_rate', 'distribution', 'deferral_rate', 'pool']).mean().loc[:,['tpr','fpr','loss_0057', 'fpr_disp']].reset_index()\n",
    "    ran_std = tests.loc[(tests['model'] == model) & (tests['training_seed'] != 'no_restrictions')].groupby(by = ['batch_size', 'absence_rate', 'distribution', 'deferral_rate', 'pool']).std().loc[:,['tpr','fpr','loss_0057', 'fpr_disp']].reset_index()\n",
    "    #results[f'tpr_{model}'] = ((ran['fpr']*100).round(2)).astype(str) + '+-' + ((ran_std['fpr']*100).round(2)).astype(str)\n",
    "    #results[f'fpr_{model}'] = ((ran['tpr']*100).round(2)).astype(str) + '+-' + ((ran_std['tpr']*100).round(2)).astype(str)\n",
    "    results[f'loss_{model}'] = '$' + ((ran['loss_0057']).round(0)).astype(int).astype(str) + '\\mbox{\\scriptsize{$\\pm ' + ((1.96*ran_std['loss_0057']).round(0)).astype(int).astype(str) + '$} }$'\n",
    "    results[f'PE_{model}'] = '$' + ((ran['fpr_disp']).round(2)).astype(str)\n",
    "    results[f'PE_{model}'].loc[results[f'PE_{model}'].str.len() == 4] += '0'\n",
    "    results[f'PE_{model}'] += '$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
