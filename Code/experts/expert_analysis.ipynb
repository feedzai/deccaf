{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scen = 'alert_0.05-data_0.05'\n",
    "l = 0.057\n",
    "prop = pd.read_parquet(f'./teams/{scen}-l_{l}/expert_info/full_w_table.parquet')\n",
    "\n",
    "w = prop.drop(columns =['fp_beta', 'fn_beta', 'alpha'])\n",
    "w = w.div(np.sqrt(np.square(w).sum(axis=1)), axis = 0)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(14, 3))\n",
    "sns.heatmap(w, robust=True, cmap = 'coolwarm', vmax = 1, vmin = -1, cbar_kws = dict(use_gridspec=False,location=\"right\"))\n",
    "plt.title(\"Normalized Weight Vector Heatmap\")\n",
    "plt.xticks(rotation = 50, rotation_mode = 'anchor', ha = 'right')\n",
    "plt.savefig(\"w_heatmap.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scens = ['alert_0.05-data_0.05','alert_0.15-data_0.05']\n",
    "costs = [0.0114,0.057,0.285]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = dict()\n",
    "val_res = dict()\n",
    "train_res = dict()\n",
    "test_comp = dict()\n",
    "classifier_h = dict()\n",
    "classifier_h_properties = dict()\n",
    "for scen in scens:\n",
    "    test_res[scen] = dict()\n",
    "    val_res[scen] = dict()\n",
    "    train_res[scen] = dict()\n",
    "    test_comp[scen] = dict()\n",
    "    classifier_h[scen] = dict()\n",
    "    classifier_h_properties[scen] = dict()\n",
    "    for l in costs:\n",
    "        data = pd.read_parquet(f'../data/alerts/{scen}.parquet')\n",
    "        train = data.loc[(data[\"month\"] > 2) & (data[\"month\"] < 6)]\n",
    "        val = data.loc[data[\"month\"] == 6]\n",
    "        test = data.loc[data[\"month\"] == 7]\n",
    "\n",
    "\n",
    "        with open(f'../classifier_h/selected_models/{scen}-l_{l}/best_model.pickle', 'rb') as infile:\n",
    "            classifier_h[scen][l] = pickle.load(infile)\n",
    "\n",
    "        with open(f'../classifier_h/selected_models/{scen}-l_{l}/model_properties.yaml', 'r') as infile:\n",
    "            classifier_h_properties[scen][l] = yaml.safe_load(infile)\n",
    "\n",
    "\n",
    "        val_preds = pd.read_parquet(f'./teams/{scen}-l_{l}/expert_info/train_predictions.parquet')\n",
    "        train_test_preds = pd.read_parquet(f'./teams/{scen}-l_{l}/expert_info/deployment_predictions.parquet')\n",
    "        train_preds = train_test_preds.loc[train.index]\n",
    "        test_preds = train_test_preds.loc[test.index]\n",
    "\n",
    "        binarized_val = (val_preds>0.5).astype(int)\n",
    "        binarized_test = (test_preds>0.5).astype(int)\n",
    "        binarized_train = (train_preds>0.5).astype(int)\n",
    "\n",
    "        results_train = pd.DataFrame()\n",
    "        for agent in binarized_train.columns:\n",
    "            tn, fp, fn, tp = confusion_matrix(train['fraud_bool'], binarized_train[agent]).ravel()\n",
    "            results_train.loc[agent,'tn'] = tn\n",
    "            results_train.loc[agent,'tp'] = tp\n",
    "            results_train.loc[agent,'fn'] = fn\n",
    "            results_train.loc[agent,'fp'] = fp\n",
    "            results_train.loc[agent,'fpr'] = fp/(fp+tn)\n",
    "            results_train.loc[agent,'fnr'] = fn/(fn+tp)\n",
    "            results_train.loc[agent,'cost'] = (l*fp+fn)/(fp+fn+tp+tn)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(train['fraud_bool'], np.ones(len(train['fraud_bool']))).ravel()\n",
    "        results_train.loc['reject_all','tn'] = tn\n",
    "        results_train.loc['reject_all','tp'] = tp\n",
    "        results_train.loc['reject_all','fn'] = fn\n",
    "        results_train.loc['reject_all','fp'] = fp\n",
    "        results_train.loc['reject_all','fpr'] = fp/(fp+tn)\n",
    "        results_train.loc['reject_all','fnr'] = fn/(fn+tp)\n",
    "        results_train.loc['reject_all','cost'] = (l*fp+fn)/(fp+fn+tp+tn)\n",
    "\n",
    "        results_train['expert'] = results_train.index\n",
    "        results_train['Decisions'] = results_train['expert'].apply(lambda x: x.split('#')[0])\n",
    "        results_train.loc['model#0','Decisions'] = 'Classifier h'\n",
    "\n",
    "        results_val = pd.DataFrame()\n",
    "        for agent in binarized_val.columns:\n",
    "            tn, fp, fn, tp = confusion_matrix(val['fraud_bool'], binarized_val[agent]).ravel()\n",
    "            results_val.loc[agent,'tn'] = tn\n",
    "            results_val.loc[agent,'tp'] = tp\n",
    "            results_val.loc[agent,'fn'] = fn\n",
    "            results_val.loc[agent,'fp'] = fp\n",
    "            results_val.loc[agent,'fpr'] = fp/(fp+tn)\n",
    "            results_val.loc[agent,'fnr'] = fn/(fn+tp)\n",
    "            results_val.loc[agent,'cost'] = (l*fp+fn)/(fp+fn+tp+tn)\n",
    "\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(val['fraud_bool'], np.ones(len(val['fraud_bool']))).ravel()\n",
    "        results_val.loc['reject_all','tn'] = tn\n",
    "        results_val.loc['reject_all','tp'] = tp\n",
    "        results_val.loc['reject_all','fn'] = fn\n",
    "        results_val.loc['reject_all','fp'] = fp\n",
    "        results_val.loc['reject_all','fpr'] = fp/(fp+tn)\n",
    "        results_val.loc['reject_all','fnr'] = fn/(fn+tp)\n",
    "        results_val.loc['reject_all','cost'] = (l*fp+fn)/(fp+fn+tp+tn)\n",
    "\n",
    "        results_val['expert'] = results_val.index\n",
    "        results_val['Decisions'] = results_val['expert'].apply(lambda x: x.split('#')[0])\n",
    "        results_val.loc['model#0','Decisions'] = 'Classifier h'\n",
    "\n",
    "\n",
    "        results_test = pd.DataFrame()\n",
    "        for agent in binarized_test.columns:\n",
    "            tn, fp, fn, tp = confusion_matrix(test['fraud_bool'], binarized_test[agent]).ravel()\n",
    "            results_test.loc[agent,'tn'] = tn\n",
    "            results_test.loc[agent,'tp'] = tp\n",
    "            results_test.loc[agent,'fn'] = fn\n",
    "            results_test.loc[agent,'fp'] = fp\n",
    "            results_test.loc[agent,'fpr'] = fp/(fp+tn)\n",
    "            results_test.loc[agent,'fnr'] = fn/(fn+tp)\n",
    "            results_test.loc[agent,'cost'] = (l*fp+fn)/(fp+fn+tp+tn)\n",
    "\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(test['fraud_bool'], np.ones(len(test['fraud_bool']))).ravel()\n",
    "        results_test.loc['reject_all','tn'] = tn\n",
    "        results_test.loc['reject_all','tp'] = tp\n",
    "        results_test.loc['reject_all','fn'] = fn\n",
    "        results_test.loc['reject_all','fp'] = fp\n",
    "        results_test.loc['reject_all','fpr'] = fp/(fp+tn)\n",
    "        results_test.loc['reject_all','fnr'] = fn/(fn+tp)\n",
    "        results_test.loc['reject_all','cost'] = (l*fp+fn)/(fp+fn+tp+tn)\n",
    "\n",
    "\n",
    "        results_test['expert'] = results_test.index\n",
    "        results_test['Decisions'] = results_test['expert'].apply(lambda x: x.split('#')[0])\n",
    "        results_test.loc['model#0','Decisions'] = 'Classifier h'\n",
    "\n",
    "\n",
    "        complementary_test = pd.DataFrame(columns = binarized_test.columns, index = binarized_test.columns)\n",
    "        for a1 in binarized_test.columns:\n",
    "            for a2 in binarized_test.columns:\n",
    "                complementary_test.loc[a1,a2] = ((binarized_test[a1] == test['fraud_bool']) & (binarized_test[a2] != test['fraud_bool'])).astype(int).mean()\n",
    "        \n",
    "        test_res[scen][l] = results_test\n",
    "        val_res[scen][l] = results_val\n",
    "        train_res[scen][l] = results_train\n",
    "        test_comp[scen][l] = complementary_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 8),nrows = 2, ncols = 3,sharey = True, sharex = True)\n",
    "i=0\n",
    "pos = [[47,58,120],[40,120,100]]\n",
    "off = [[0.7,0.1,-0.1],[0.2,0.05,-0.08]]\n",
    "titles = [[r'$a_r = 0.05$, $\\lambda = 0.0114$',r'$a_r = 0.05$, $\\lambda = 0.057$',r'$a_r = 0.05$, $\\lambda = 0.285$'],\n",
    "[r'$a_r = 0.15$, $\\lambda = 0.0114$',r'$a_r = 0.15$, $\\lambda = 0.057$',r'$a_r = 0.15$, $\\lambda = 0.285$']]\n",
    "for scen in scens:\n",
    "    j = 0\n",
    "    for l in costs:\n",
    "        test_res[scen][l].replace({'standard':'Experts'},inplace = True)\n",
    "        prev = classifier_h_properties[scen][l]['prev_test']\n",
    "        cost = test_res[scen][l].loc['reject_all','cost']\n",
    "        slope = -(prev)/(l*(1-prev))\n",
    "        b = cost/(l*(1-prev))\n",
    "        ax[i][j].plot(np.arange(0,1,0.001), np.arange(0,1,0.001)*slope + b, color = 'tomato')\n",
    "        ax[i][j].text(np.arange(0,1,0.001)[pos[i][j]], np.arange(0,1,0.001)[pos[i][j]]*slope + b + off[i][j], f'Cost of Full Alert Rejection = {cost:.3f}', color = 'darkred', rotation = 360*np.arctan(slope)/(2*np.pi), rotation_mode = 'anchor')\n",
    "        ax[i][j].fill_between(x=np.arange(0,1.001,0.001),y1 = np.arange(0,1.001,0.001)*slope + b, alpha = 0.2, color = 'green')\n",
    "        ax[i][j].fill_between(x=np.arange(0,1.001,0.001),y1 = np.arange(0,1.001,0.001)*slope + b, y2 = np.ones(len(np.arange(0,1.001,0.001))), alpha = 0.2, color = 'tomato')\n",
    "        prev = classifier_h_properties[scen][l]['prev_test']\n",
    "        cost = classifier_h_properties[scen][l]['cost_test']\n",
    "        slope = -(prev)/(l*(1-prev))\n",
    "        b = cost/(l*(1-prev))\n",
    "        sns.scatterplot(ax = ax[i][j], data=test_res[scen][l].drop('reject_all'), x='fnr', y='fpr', hue='Decisions', style='Decisions',  palette=[\"C0\", \"C1\"], s = 70)\n",
    "        ax[i][j].plot(np.arange(0,1,0.01), np.arange(0,1,0.01)*slope + b)\n",
    "\n",
    "        ax[i][j].set_ylim([0,1])\n",
    "        ax[i][j].set_xlim([0,1])\n",
    "        ax[i][j].set_xlabel('FNR')\n",
    "        ax[i][j].set_ylabel('FPR')\n",
    "        ax[i][j].set_title(titles[i][j])\n",
    "        ax[i][j].legend(loc = 'upper right')\n",
    "        \n",
    "        j+=1\n",
    "    i+=1\n",
    "\n",
    "plt.savefig(\"FPR_FNR_EXPERTS.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12*0.9, 8*0.9),nrows = 2, ncols = 3,sharey = True, sharex = True)\n",
    "i=0\n",
    "cbar_ax = f.add_axes([.91, .3, .03, .4])\n",
    "titles = [[r'$a_r = 0.05$, $\\lambda = 0.0114$',r'$a_r = 0.05$, $\\lambda = 0.057$',r'$a_r = 0.05$, $\\lambda = 0.285$'],\n",
    "[r'$a_r = 0.15$, $\\lambda = 0.0114$',r'$a_r = 0.15$, $\\lambda = 0.057$',r'$a_r = 0.15$, $\\lambda = 0.285$']]\n",
    "for scen in scens:\n",
    "    j = 0\n",
    "    for l in costs:\n",
    "        test_comp[scen][l].rename(index = {\n",
    "            'standard#0':'Expert#0',\n",
    "            'standard#1':'Expert#1',\n",
    "            'standard#2':'Expert#2',\n",
    "            'standard#3':'Expert#3',\n",
    "            'standard#5':'Expert#5',\n",
    "            'standard#4':'Expert#4',\n",
    "            'standard#6':'Expert#6',\n",
    "            'standard#7':'Expert#7',\n",
    "            'standard#8':'Expert#8',\n",
    "            'model#0':'Class. h',\n",
    "\n",
    "        }, columns = {\n",
    "            'standard#0':'Expert#0',\n",
    "            'standard#1':'Expert#1',\n",
    "            'standard#2':'Expert#2',\n",
    "            'standard#3':'Expert#3',\n",
    "            'standard#4':'Expert#4',\n",
    "            'standard#5':'Expert#5',\n",
    "            'standard#6':'Expert#6',\n",
    "            'standard#7':'Expert#7',\n",
    "            'standard#8':'Expert#8',\n",
    "            'model#0':'Class. h',\n",
    "\n",
    "        }, inplace = True)\n",
    "        sns.heatmap(ax = ax[i][j], data=test_comp[scen][l].astype(float),vmin = 0, vmax = 1, cbar = (j==0)&(i==0), cbar_ax = cbar_ax)\n",
    "\n",
    "        ax[i][j].set_title(titles[i][j])\n",
    "        t = ax[i][j].get_xticklabels()\n",
    "        ax[i][j].set_xticklabels(t, rotation = 50, rotation_mode = 'anchor', ha = 'right')\n",
    "        \n",
    "        \n",
    "        j+=1\n",
    "    i+=1\n",
    "\n",
    "\n",
    "f.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "plt.savefig(\"Complementarity.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
